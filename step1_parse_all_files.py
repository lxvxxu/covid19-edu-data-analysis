"""
STEP 1: ìƒí™œê¸°ë¡ë¶€ íŒŒì‹± (OCR í˜¸í™˜ ë²„ì „)
========================================
ê°œì„ ì‚¬í•­:
1. OCR ë³€í™˜ í…ìŠ¤íŠ¸ íŒŒì‹± ì§€ì› (ê³µë°± ë¶ˆê·œì¹™ ì²˜ë¦¬)
2. ì„¸íŠ¹ íŒŒì‹± íŒ¨í„´ ê°œì„ 
3. ì²´ìœ¡/ì˜ˆìˆ  ì„±ì  íŒŒì‹± ì¶”ê°€
4. ì½”ë¡œë‚˜ ê¸°ê°„: 2020.3 ~ 2022.3 (2020~2022ë…„)
5. thefuzz í¼ì§€ ë§¤ì¹­
6. SHA-256 ë¹„ì‹ë³„í™”
"""

import os
import re
import hashlib
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# thefuzz ì„í¬íŠ¸
try:
    from thefuzz import fuzz, process
    FUZZY_AVAILABLE = True
    print("âœ… thefuzz ë¡œë“œ ì™„ë£Œ")
except ImportError:
    FUZZY_AVAILABLE = False
    print("âš ï¸  thefuzz ë¯¸ì„¤ì¹˜ - ê¸°ë³¸ ë§¤ì¹­ ì‚¬ìš© (pip install thefuzz python-Levenshtein)")


class StudentRecordParser:
    """ìƒí™œê¸°ë¡ë¶€ íŒŒì„œ (OCR í˜¸í™˜ ë²„ì „)"""
    
    def __init__(self):
        # êµìœ¡ë¶€ ê³µì‹ ê³¼ëª© ë¦¬ìŠ¤íŠ¸
        self.all_subjects = [
            'êµ­ì–´', 'êµ­ì–´â… ', 'êµ­ì–´â…¡', 'êµ­ì–´ I', 'êµ­ì–´ II',
            'ìˆ˜í•™', 'ìˆ˜í•™â… ', 'ìˆ˜í•™â…¡', 'ìˆ˜í•™ I', 'ìˆ˜í•™ II',
            'ì˜ì–´', 'ì˜ì–´â… ', 'ì˜ì–´â…¡', 'ì˜ì–´ I', 'ì˜ì–´ II',
            'í™”ë²•ê³¼ ì‘ë¬¸', 'í™”ë²•ê³¼ì‘ë¬¸', 'ë…ì„œì™€ ë¬¸ë²•', 'ë…ì„œì™€ë¬¸ë²•',
            'ë¬¸í•™', 'ë…ì„œ', 'ì–¸ì–´ì™€ ë§¤ì²´',
            'ë¯¸ì ë¶„â… ', 'ë¯¸ì ë¶„â…¡', 'ë¯¸ì ë¶„ I', 'ë¯¸ì ë¶„ II', 'ë¯¸ì ë¶„',
            'í™•ë¥ ê³¼ í†µê³„', 'í™•ë¥ ê³¼í†µê³„', 'ê¸°í•˜ì™€ ë²¡í„°', 'ê¸°í•˜ì™€ë²¡í„°', 'ê¸°í•˜',
            'ì‹¤ìš©ì˜ì–´â… ', 'ì‹¤ìš©ì˜ì–´â…¡', 'ì‹¤ìš©ì˜ì–´ I', 'ì‹¤ìš©ì˜ì–´ II', 'ì‹¤ìš©ì˜ì–´',
            'ì˜ì–´íšŒí™”', 'ì˜ì–´ë…í•´ì™€ ì‘ë¬¸', 'ì˜ì–´ë…í•´ì™€ì‘ë¬¸',
            'í•œêµ­ì‚¬', 'í•œêµ­ì§€ë¦¬', 'ì„¸ê³„ì§€ë¦¬', 'ì„¸ê³„ì‚¬', 'ë™ì•„ì‹œì•„ì‚¬',
            'ê²½ì œ', 'ì •ì¹˜ì™€ ë²•', 'ë²•ê³¼ì •ì¹˜', 'ì‚¬íšŒÂ·ë¬¸í™”', 'ì‚¬íšŒë¬¸í™”', 'ì‚¬íšŒ',
            'ìƒí™œê³¼ ìœ¤ë¦¬', 'ìœ¤ë¦¬ì™€ ì‚¬ìƒ', 'ìœ¤ë¦¬ì™€ì‚¬ìƒ',
            'ë¬¼ë¦¬í•™â… ', 'ë¬¼ë¦¬í•™â…¡', 'ë¬¼ë¦¬ I', 'ë¬¼ë¦¬ II', 'ë¬¼ë¦¬í•™ I', 'ë¬¼ë¦¬í•™ II',
            'í™”í•™â… ', 'í™”í•™â…¡', 'í™”í•™ I', 'í™”í•™ II', 'í™”í•™',
            'ìƒëª…ê³¼í•™â… ', 'ìƒëª…ê³¼í•™â…¡', 'ìƒëª…ê³¼í•™ I', 'ìƒëª…ê³¼í•™ II', 'ìƒëª…ê³¼í•™',
            'ì§€êµ¬ê³¼í•™â… ', 'ì§€êµ¬ê³¼í•™â…¡', 'ì§€êµ¬ê³¼í•™ I', 'ì§€êµ¬ê³¼í•™ II', 'ì§€êµ¬ê³¼í•™',
            'ê³¼í•™', 'ìœµí•©ê³¼í•™', 'ê³¼í•™íƒêµ¬ì‹¤í—˜',
            'ì²´ìœ¡', 'ìš´ë™ê³¼ ê±´ê°•', 'ìŠ¤í¬ì¸  ìƒí™œ', 'ìŠ¤í¬ì¸ ë¬¸í™”', 'ìŠ¤í¬ì¸ ê³¼í•™',
            'ìŒì•…', 'ìŒì•…ê³¼ìƒí™œ', 'ìŒì•…ê³¼ì§„ë¡œ', 'ìŒì•… ê°ìƒê³¼ ë¹„í‰',
            'ë¯¸ìˆ ', 'ë¯¸ìˆ ì°½ì‘', 'ë¯¸ìˆ  ê°ìƒê³¼ ë¹„í‰',
            'ê¸°ìˆ Â·ê°€ì •', 'ê¸°ìˆ  . ê°€ì •', 'ê¸°ìˆ ê°€ì •', 'ì •ë³´',
            'í•œë¬¸â… ', 'í•œë¬¸â…¡', 'í•œë¬¸ I', 'í•œë¬¸ II', 'í•œë¬¸',
            'ì¤‘êµ­ì–´â… ', 'ì¤‘êµ­ì–´â…¡', 'ì¤‘êµ­ì–´ I', 'ì¤‘êµ­ì–´ II',
            'ì¼ë³¸ì–´â… ', 'ì¼ë³¸ì–´â…¡', 'ì¼ë³¸ì–´ I', 'ì¼ë³¸ì–´ II',
            'ë…ì¼ì–´â… ', 'í”„ë‘ìŠ¤ì–´â… ', 'ìŠ¤í˜ì¸ì–´â… ',
            'ì‹¤ìš©ê²½ì œ', 'ë…¼ìˆ ', 'ì§„ë¡œì™€ ì§ì—…', 'ì² í•™', 'ì‹¬ë¦¬í•™', 'êµìœ¡í•™',
            'ê³ ì „', 'ê³ ì „ì½ê¸°',
        ]
        
        # êµê³¼êµ° ë§¤í•‘
        self.subject_to_group = self._build_subject_group_map()
        
        # í‚¤ì›Œë“œ
        self.exploration_keywords = [
            'ì‹¤í—˜', 'ì‹¤ìŠµ', 'ê´€ì°°', 'ì¸¡ì •', 'ë¶„ì„', 'íƒêµ¬', 'ì—°êµ¬', 'ì¡°ì‚¬',
            'íƒìƒ‰', 'ë°œê²¬', 'í˜„ì¥', 'ë‹µì‚¬', 'ê²¬í•™', 'ë°©ë¬¸', 'ì²´í—˜',
            'í”„ë¡œì íŠ¸', 'ê³¼ì œì—°êµ¬', 'íŒ€í”„ë¡œì íŠ¸', 'ëª¨ë‘ í™œë™',
            'ê°€ì„¤', 'ê²€ì¦', 'ì‹¤í—˜ì„¤ê³„', 'ë°ì´í„°', 'ê²°ê³¼ë¶„ì„', 'ë³´ê³ ì„œ'
        ]
        
        self.online_keywords = [
            'ì˜¨ë¼ì¸', 'ì›ê²©', 'ë¹„ëŒ€ë©´', 'í™”ìƒ', 'ì‹¤ì‹œê°„', 'ìŒë°©í–¥',
            'zoom', 'ì¤Œ', 'êµ¬ê¸€í´ë˜ìŠ¤ë£¸', 'e-í•™ìŠµí„°', 'ì´í•™ìŠµí„°',
            'EBS', 'ebs', 'ìœ„ë‘ë‘', 'ë””ì§€í„¸', 'ì¸í„°ë„·', 'ì›ê²©ìˆ˜ì—…',
            'ì˜¨ë¼ì¸ìˆ˜ì—…', 'í™”ìƒìˆ˜ì—…', 'ë™ì˜ìƒ', 'ì˜ìƒ'
        ]
        
        self.qualitative_keywords = [
            'ê³¼ì •', 'ë…¸ë ¥', 'íƒœë„', 'ì°¸ì—¬', 'ì—´ì •', 'ëª°ì…', 'ì§‘ì¤‘',
            'í˜‘ë ¥', 'í˜‘ë™', 'ë°°ë ¤', 'ë‚˜ëˆ”', 'ì†Œí†µ', 'ê³µê°', 'ì¡´ì¤‘',
            'ì„±ì¥', 'ë°œì „', 'ê°œì„ ', 'ê·¹ë³µ', 'ë„ì „', 'ë³€í™”'
        ]
        
        # ì„±ì  ë“±ê¸‰ ë§¤í•‘
        self.grade_map = {
            'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5,
            '1': 1, '2': 2, '3': 3, '4': 4, '5': 5,
            '6': 6, '7': 7, '8': 8, '9': 9,
            'ìˆ˜': 1, 'ìš°': 2, 'ë¯¸': 3, 'ì–‘': 4, 'ê°€': 5,
            'P': 0  # Pass
        }
    
    def _build_subject_group_map(self) -> Dict[str, str]:
        """êµê³¼êµ° ë§¤í•‘"""
        mapping = {}
        for subject in self.all_subjects:
            subj_lower = subject.lower()
            if any(kw in subject for kw in ['êµ­ì–´', 'í™”ë²•', 'ì‘ë¬¸', 'ë…ì„œ', 'ì–¸ì–´', 'ë¬¸í•™', 'ê³ ì „']):
                mapping[subject] = 'êµ­ì–´'
            elif any(kw in subject for kw in ['ìˆ˜í•™', 'ë¯¸ì ë¶„', 'í™•ë¥ ', 'í†µê³„', 'ê¸°í•˜']):
                mapping[subject] = 'ìˆ˜í•™'
            elif any(kw in subject for kw in ['ì˜ì–´', 'English']):
                mapping[subject] = 'ì˜ì–´'
            elif any(kw in subject for kw in ['ì—­ì‚¬', 'í•œêµ­ì‚¬', 'ì„¸ê³„ì‚¬', 'ë™ì•„ì‹œì•„', 'ì§€ë¦¬', 'ê²½ì œ', 'ì •ì¹˜', 'ë²•', 'ì‚¬íšŒ', 'ìœ¤ë¦¬']):
                mapping[subject] = 'ì‚¬íšŒ'
            elif any(kw in subject for kw in ['ê³¼í•™', 'ë¬¼ë¦¬', 'í™”í•™', 'ìƒëª…', 'ì§€êµ¬', 'ìœµí•©']):
                mapping[subject] = 'ê³¼í•™'
            elif any(kw in subject for kw in ['ì²´ìœ¡', 'ìš´ë™', 'ìŠ¤í¬ì¸ ']):
                mapping[subject] = 'ì²´ìœ¡'
            elif any(kw in subject for kw in ['ìŒì•…', 'ë¯¸ìˆ ', 'ì—°ê·¹', 'ì˜ˆìˆ ']):
                mapping[subject] = 'ì˜ˆìˆ '
            elif any(kw in subject for kw in ['ê¸°ìˆ ', 'ê°€ì •', 'ì •ë³´']):
                mapping[subject] = 'ê¸°ìˆ ê°€ì •'
            elif any(kw in subject for kw in ['ë…ì¼ì–´', 'í”„ë‘ìŠ¤ì–´', 'ìŠ¤í˜ì¸ì–´', 'ì¤‘êµ­ì–´', 'ì¼ë³¸ì–´', 'í•œë¬¸']):
                mapping[subject] = 'ì œ2ì™¸êµ­ì–´'
            else:
                mapping[subject] = 'êµì–‘'
        return mapping
    
    @staticmethod
    def generate_anonymous_id(name: str, student_id: str) -> str:
        """SHA-256 ë¹„ì‹ë³„í™”"""
        combined = f"{name}_{student_id}"
        return hashlib.sha256(combined.encode('utf-8')).hexdigest()[:16]
    
    def fuzzy_match_subject(self, query: str, threshold: int = 70) -> Tuple[Optional[str], int]:
        """í¼ì§€ ë§¤ì¹­"""
        if not query or len(query) < 2:
            return None, 0
        
        # ì •í™• ë§¤ì¹­
        if query in self.all_subjects:
            return query, 100
        
        # ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ ë§¤ì¹­
        cleaned = re.sub(r'[\s./]+', '', query)
        for subject in self.all_subjects:
            cleaned_subj = re.sub(r'[\s./]+', '', subject)
            if cleaned == cleaned_subj:
                return subject, 100
        
        # thefuzz í¼ì§€ ë§¤ì¹­
        if FUZZY_AVAILABLE:
            result = process.extractOne(query, self.all_subjects, scorer=fuzz.token_sort_ratio)
            if result and result[1] >= threshold:
                return result[0], result[1]
        
        # ë¶€ë¶„ ë§¤ì¹­
        for subject in self.all_subjects:
            if query in subject or subject in query:
                return subject, 80
        
        return query, 50  # ë§¤ì¹­ ì‹¤íŒ¨í•´ë„ ì›ë³¸ ë°˜í™˜
    
    def extract_years_from_text(self, text: str) -> List[int]:
        """ì—°ë„ ì¶”ì¶œ"""
        patterns = [
            r'(20\d{2})[\.,\-/]\s*\d{1,2}[\.,\-/]\s*\d{1,2}',
            r'\((20\d{2})\)',
            r'(20\d{2})ë…„',
            r'(20\d{2})í•™ë…„',
        ]
        
        all_years = []
        for pattern in patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                try:
                    year = int(match)
                    if 2010 <= year <= 2025:
                        all_years.append(year)
                except:
                    pass
        return all_years
    
    def estimate_grade_years(self, text: str, filename: str) -> Dict[int, int]:
        """í•™ë…„ë³„ ì—°ë„ ì¶”ì •"""
        grade_years = {}
        
        # ìˆ˜ìƒê²½ë ¥ì—ì„œ íŒ¨í„´ ì°¾ê¸°
        patterns = [
            r'(20\d{2})[\./\-]\d{1,2}[\./\-]\d{1,2}.*?(\d)í•™ë…„',
            r'(\d)í•™ë…„.*?(20\d{2})',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                try:
                    if match[0].isdigit() and len(match[0]) == 4:
                        year, grade = int(match[0]), int(match[1])
                    else:
                        grade, year = int(match[0]), int(match[1])
                    if 1 <= grade <= 3 and 2010 <= year <= 2025:
                        if grade not in grade_years:
                            grade_years[grade] = year
                except:
                    pass
        
        # ì—°ë„ë§Œ ì¶”ì¶œí•´ì„œ ì¶”ì •
        if not grade_years:
            all_years = self.extract_years_from_text(text)
            if all_years:
                year_counts = Counter(all_years)
                common_years = sorted(year_counts.keys())
                if len(common_years) >= 1:
                    base_year = min(common_years)
                    for i, grade in enumerate([1, 2, 3]):
                        grade_years[grade] = base_year + i
        
        return grade_years
    
    def parse_student_info(self, text: str, filename: str) -> Dict:
        """í•™ìƒ ê¸°ë³¸ ì •ë³´ íŒŒì‹±"""
        # íŒŒì¼ëª…ì—ì„œ ì •ë³´ ì¶”ì¶œ
        parts = filename.replace('.txt', '').split('_')
        
        student_id = parts[0] if parts else "unknown"
        grade_level = re.search(r'(\d)í•™ë…„', filename)
        grade_level = int(grade_level.group(1)) if grade_level else 0
        major = parts[2] if len(parts) > 2 else "unknown"
        name = parts[3] if len(parts) > 3 else "unknown"
        admission = parts[4] if len(parts) > 4 else "unknown"
        
        # ë¹„ì‹ë³„í™” ID
        anonymous_id = self.generate_anonymous_id(name, student_id)
        
        # í•™ë…„ë³„ ì—°ë„ ì¶”ì •
        grade_years = self.estimate_grade_years(text, filename)
        
        # ì½”ë¡œë‚˜ ì—¬ë¶€ íŒë‹¨ (2020ë…„ 3ì›” ~ 2022ë…„ 3ì›” = 2020~2022ë…„)
        grade1_covid = 1 if grade_years.get(1) and 2020 <= grade_years[1] <= 2022 else 0
        grade2_covid = 1 if grade_years.get(2) and 2020 <= grade_years[2] <= 2022 else 0
        grade3_covid = 1 if grade_years.get(3) and 2020 <= grade_years[3] <= 2022 else 0
        
        # ì½”ë¡œë‚˜ ê°•ë„ (0~3)
        covid_intensity = grade1_covid + grade2_covid + grade3_covid
        any_covid = 1 if covid_intensity > 0 else 0
        
        return {
            'student_id': anonymous_id,
            'anonymous_id': anonymous_id,
            'original_id': student_id,
            'name_hash': hashlib.sha256(name.encode()).hexdigest()[:8],
            'major': major,
            'admission_type': admission,
            'current_grade': grade_level,
            
            # í•™ë…„ë³„ ì—°ë„
            'grade_year_1': grade_years.get(1),
            'grade_year_2': grade_years.get(2),
            'grade_year_3': grade_years.get(3),
            'grade1_year': grade_years.get(1),
            'grade2_year': grade_years.get(2),
            'grade3_year': grade_years.get(3),
            'hs_graduation_year': grade_years.get(3) + 1 if grade_years.get(3) else None,
            'graduation_year': grade_years.get(3) + 1 if grade_years.get(3) else None,
            
            # ì½”ë¡œë‚˜ ê´€ë ¨
            'grade1_covid': grade1_covid,
            'grade2_covid': grade2_covid,
            'grade3_covid': grade3_covid,
            'covid_intensity': covid_intensity,
            'any_covid': any_covid,
            'has_covid': any_covid,
            'has_covid_period': any_covid,
            'covid_period': any_covid,
            
            # ì¬ìˆ˜ ì—¬ë¶€
            'is_repeat': 0,
        }
    
    def extract_grades(self, text: str, student_id: str, grade_years: Dict) -> List[Dict]:
        """ì„±ì  ë°ì´í„° ì¶”ì¶œ (OCR í˜¸í™˜)"""
        grades = []
        
        # OCR í…ìŠ¤íŠ¸ ì •ë¦¬ (ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°)
        cleaned_text = re.sub(r'\s+', ' ', text)
        
        # í•™ë…„ë³„ ì„¹ì…˜ ë¶„ë¦¬
        grade_sections = re.split(r'\[(\d)í•™ë…„\]', cleaned_text)
        
        # ì¼ë°˜ ê³¼ëª© ì„±ì  íŒ¨í„´ (OCR í˜¸í™˜)
        # íŒ¨í„´: êµê³¼ ê³¼ëª© ë‹¨ìœ„ìˆ˜ ì›ì ìˆ˜/í‰ê· (í‘œì¤€í¸ì°¨) ì„±ì·¨ë„(ìˆ˜ê°•ììˆ˜) [ì„ì°¨ë“±ê¸‰]
        patterns = [
            # í‘œì¤€ íŒ¨í„´
            r'([ê°€-í£A-Za-z\s./â… â…¡]+?)\s+(\d+)\s+(\d+)\s*/\s*(\d+\.?\s*\d*)\s*\(\s*(\d+\.?\s*\d*)\s*\)\s+([A-EP])\s*\(\s*(\d+)\s*\)\s*(\d)?',
            # ê°„ë‹¨ íŒ¨í„´
            r'([ê°€-í£]+)\s+([ê°€-í£A-Za-zâ… â…¡\s]+?)\s+(\d+)\s+(\d+)\s*/\s*(\d+\.?\d*)\s*\((\d+\.?\d*)\)\s+([A-EP])\s*\((\d+)\)',
        ]
        
        for i in range(1, len(grade_sections), 2):
            try:
                grade_year = int(grade_sections[i])
                section_text = grade_sections[i + 1] if i + 1 < len(grade_sections) else ""
                year = grade_years.get(grade_year)
                
                for pattern in patterns:
                    for match in re.finditer(pattern, section_text):
                        try:
                            groups = match.groups()
                            subject_raw = groups[0].strip() if len(groups[0]) > 1 else groups[1].strip() if len(groups) > 1 else ""
                            
                            # ìˆ«ì ì •ë¦¬ (OCR ì˜¤ë¥˜ ìˆ˜ì •)
                            def clean_num(s):
                                return float(re.sub(r'\s+', '', str(s)))
                            
                            subject_matched, score = self.fuzzy_match_subject(subject_raw)
                            subject = subject_matched if subject_matched else subject_raw
                            
                            # ì„±ì·¨ë„ ì°¾ê¸°
                            achievement = None
                            for g in groups:
                                if g and g in 'ABCDEP':
                                    achievement = g
                                    break
                            
                            if not achievement:
                                continue
                            
                            grade_numeric = self.grade_map.get(achievement, 3)
                            grade_type = 'achievement' if achievement in 'ABCDEP' else 'rank'
                            
                            grades.append({
                                'student_id': student_id,
                                'grade_year': grade_year,
                                'year': year,
                                'term': 1,
                                'subject': subject,
                                'subject_raw': subject_raw,
                                'subject_group': self.subject_to_group.get(subject, 'êµì–‘'),
                                'achievement': achievement,
                                'grade_numeric': grade_numeric,
                                'grade_type': grade_type,
                                'match_score': score,
                            })
                        except:
                            pass
            except:
                pass
        
        # ì²´ìœ¡/ì˜ˆìˆ  ì„±ì  íŒŒì‹±
        pe_art_pattern = r'<\s*ì²´ìœ¡\s*[.Â·]\s*ì˜ˆìˆ .*?>'
        pe_art_sections = re.split(pe_art_pattern, cleaned_text)
        
        # ì²´ìœ¡/ì˜ˆìˆ  íŒ¨í„´: êµê³¼ ê³¼ëª© ë‹¨ìœ„ìˆ˜ ì„±ì·¨ë„ ë‹¨ìœ„ìˆ˜ ì„±ì·¨ë„
        pe_pattern = r'(ì²´ìœ¡|ì˜ˆìˆ [^ê°€-í£]*)\s+([ê°€-í£A-Za-z\s]+?)\s+(\d+)\s+([A-EP])\s+(\d+)\s+([A-EP])'
        
        for section in pe_art_sections[1:] if len(pe_art_sections) > 1 else [cleaned_text]:
            for match in re.finditer(pe_pattern, section):
                try:
                    subject_group = match.group(1).strip()
                    subject = match.group(2).strip()
                    
                    # 1í•™ê¸°
                    achievement1 = match.group(4)
                    grades.append({
                        'student_id': student_id,
                        'grade_year': 1,
                        'term': 1,
                        'subject': subject,
                        'subject_raw': subject,
                        'subject_group': 'ì²´ìœ¡' if 'ì²´ìœ¡' in subject_group else 'ì˜ˆìˆ ',
                        'achievement': achievement1,
                        'grade_numeric': self.grade_map.get(achievement1, 1),
                        'grade_type': 'achievement',
                    })
                    
                    # 2í•™ê¸°
                    achievement2 = match.group(6)
                    grades.append({
                        'student_id': student_id,
                        'grade_year': 1,
                        'term': 2,
                        'subject': subject,
                        'subject_raw': subject,
                        'subject_group': 'ì²´ìœ¡' if 'ì²´ìœ¡' in subject_group else 'ì˜ˆìˆ ',
                        'achievement': achievement2,
                        'grade_numeric': self.grade_map.get(achievement2, 1),
                        'grade_type': 'achievement',
                    })
                except:
                    pass
        
        return grades
    
    def extract_seteuk(self, text: str, student_id: str, grade_years: Dict) -> List[Dict]:
        """ì„¸íŠ¹ ë°ì´í„° ì¶”ì¶œ (OCR í˜¸í™˜)"""
        seteuk_list = []
        
        # OCR í…ìŠ¤íŠ¸ ì •ë¦¬
        cleaned_text = text.replace('\n', ' ')
        
        # ì„¸íŠ¹ ì„¹ì…˜ ì°¾ê¸° (OCR ë³€í™˜ëœ í˜•íƒœ í¬í•¨)
        seteuk_patterns = [
            r'ì„¸\s*ë¶€\s*ëŠ¥\s*ë ¥\s*ë°\s*íŠ¹\s*ê¸°\s*ì‚¬\s*í•­',
            r'ì„¸ë¶€\s*ëŠ¥ë ¥\s*ë°\s*íŠ¹ê¸°ì‚¬í•­',
            r'ì„¸ë¶€ëŠ¥ë ¥íŠ¹ê¸°ì‚¬í•­',
            r'ì„¸ë¶€ëŠ¥ë ¥\s*ë°\s*íŠ¹ê¸°\s*ì‚¬í•­',
        ]
        
        seteuk_start = None
        for pattern in seteuk_patterns:
            match = re.search(pattern, cleaned_text)
            if match:
                seteuk_start = match.end()
                break
        
        if seteuk_start is None:
            return seteuk_list
        
        # ì„¸íŠ¹ ë ì°¾ê¸°
        end_patterns = [r'\d+\.\s*[ê°€-í£]+', r'<\s*ì²´ìœ¡', r'\[\dí•™ë…„\]']
        seteuk_end = len(cleaned_text)
        for pattern in end_patterns:
            match = re.search(pattern, cleaned_text[seteuk_start:])
            if match:
                seteuk_end = min(seteuk_end, seteuk_start + match.start())
        
        seteuk_text = cleaned_text[seteuk_start:seteuk_end]
        
        # ê³¼ëª©ë³„ ì„¸íŠ¹ ì¶”ì¶œ (ê³¼ëª©ëª…: ë‚´ìš© í˜•íƒœ)
        subject_pattern = r'([ê°€-í£A-Za-zâ… â…¡\s]+?)\s*:\s*(.+?)(?=[ê°€-í£A-Za-zâ… â…¡\s]+?\s*:|$)'
        
        for match in re.finditer(subject_pattern, seteuk_text, re.DOTALL):
            subject = match.group(1).strip()
            content = match.group(2).strip()
            
            # ë„ˆë¬´ ì§§ì€ ë‚´ìš© ì œì™¸
            if len(content) < 20:
                continue
            
            # ê³¼ëª©ëª… ì •ë¦¬
            subject = re.sub(r'\s+', ' ', subject)
            subject_matched, _ = self.fuzzy_match_subject(subject)
            if subject_matched:
                subject = subject_matched
            
            # í‚¤ì›Œë“œ ë¹ˆë„
            content_len = len(content)
            exp_count = sum(1 for kw in self.exploration_keywords if kw in content)
            online_count = sum(1 for kw in self.online_keywords if kw in content)
            qual_count = sum(1 for kw in self.qualitative_keywords if kw in content)
            
            seteuk_list.append({
                'student_id': student_id,
                'subject': subject,
                'content_length': content_len,
                'kw_count_exploration': exp_count,
                'kw_count_online': online_count,
                'kw_count_qualitative': qual_count,
                'kw_freq_exploration': exp_count / content_len * 1000 if content_len > 0 else 0,
                'kw_freq_online': online_count / content_len * 1000 if content_len > 0 else 0,
                'kw_freq_qualitative': qual_count / content_len * 1000 if content_len > 0 else 0,
            })
        
        return seteuk_list
    
    def calculate_volatility(self, grades: List[Dict], student_id: str) -> Dict:
        """ì„±ì  ë³€ë™ì„± ê³„ì‚°"""
        result = {'student_id': student_id}
        
        if not grades:
            result['overall_volatility'] = 0
            result['overall_mean'] = 0
            result['overall_count'] = 0
            return result
        
        df = pd.DataFrame(grades)
        
        # ì „ì²´ ë³€ë™ì„±
        if 'grade_numeric' in df.columns and len(df) > 0:
            valid = df['grade_numeric'].dropna()
            result['overall_volatility'] = valid.std() if len(valid) > 1 else 0
            result['overall_mean'] = valid.mean() if len(valid) > 0 else 0
            result['overall_count'] = len(valid)
        
        # í•™ë…„ë³„ ë³€ë™ì„±
        for grade in [1, 2, 3]:
            grade_df = df[df['grade_year'] == grade] if 'grade_year' in df.columns else pd.DataFrame()
            if len(grade_df) >= 2 and 'grade_numeric' in grade_df.columns:
                valid = grade_df['grade_numeric'].dropna()
                result[f'grade{grade}_volatility'] = valid.std() if len(valid) > 1 else 0
                result[f'grade{grade}_mean'] = valid.mean()
                result[f'grade{grade}_count'] = len(valid)
            else:
                result[f'grade{grade}_volatility'] = 0
                result[f'grade{grade}_mean'] = 0
                result[f'grade{grade}_count'] = 0
        
        return result


def create_yearly_covid_data(df_students: pd.DataFrame) -> pd.DataFrame:
    """yearly_covid.csv ìƒì„±"""
    yearly_data = []
    
    for _, student in df_students.iterrows():
        student_id = student.get('anonymous_id', student.get('student_id'))
        
        for grade in [1, 2, 3]:
            year = student.get(f'grade_year_{grade}')
            covid = student.get(f'grade{grade}_covid', 0)
            
            if pd.notna(year) and year is not None:
                yearly_data.append({
                    'anonymous_id': student_id,
                    'student_id': student_id,
                    'grade': grade,
                    'year': int(year),
                    'is_covid_period': int(covid) if pd.notna(covid) else 0,
                })
    
    return pd.DataFrame(yearly_data)


def create_keywords_data(df_seteuk: pd.DataFrame) -> pd.DataFrame:
    """keywords.csv ìƒì„±"""
    if df_seteuk.empty:
        return pd.DataFrame()
    
    keywords = df_seteuk.groupby('student_id').agg({
        'kw_count_exploration': 'sum',
        'kw_count_online': 'sum',
        'kw_count_qualitative': 'sum',
    }).reset_index()
    
    keywords.columns = ['anonymous_id', 'exploration_total', 'remote_total', 'qualitative_total']
    return keywords


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("\n" + "="*80)
    print("STEP 1: ìƒí™œê¸°ë¡ë¶€ íŒŒì‹± (OCR í˜¸í™˜ ë²„ì „)")
    print("="*80)
    
    parser = StudentRecordParser()
    
    # ë°ì´í„° ë””ë ‰í† ë¦¬
    raw_dir = Path('data/raw')
    processed_dir = Path('data/processed')
    processed_dir.mkdir(parents=True, exist_ok=True)
    
    # txt íŒŒì¼ ì°¾ê¸°
    txt_files = list(raw_dir.glob('*.txt'))
    print(f"\nì´ {len(txt_files)}ê°œ íŒŒì¼ ë°œê²¬")
    
    if not txt_files:
        print("âš ï¸  data/raw/ ë””ë ‰í† ë¦¬ì— txt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # ë°ì´í„° ì €ì¥
    all_students = []
    all_grades = []
    all_seteuk = []
    all_volatility = []
    
    print("\níŒŒì‹± ì§„í–‰ ì¤‘...")
    for i, filepath in enumerate(txt_files, 1):
        print(f"  [{i}/{len(txt_files)}] {filepath.name}...", end=' ')
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                text = f.read()
        except:
            try:
                with open(filepath, 'r', encoding='cp949') as f:
                    text = f.read()
            except:
                print("âŒ ì¸ì½”ë”© ì˜¤ë¥˜")
                continue
        
        try:
            # í•™ìƒ ì •ë³´
            student_info = parser.parse_student_info(text, filepath.name)
            student_id = student_info['anonymous_id']
            grade_years = {
                1: student_info.get('grade_year_1'),
                2: student_info.get('grade_year_2'),
                3: student_info.get('grade_year_3'),
            }
            
            # ì„±ì 
            grades = parser.extract_grades(text, student_id, grade_years)
            
            # ì„¸íŠ¹
            seteuk = parser.extract_seteuk(text, student_id, grade_years)
            
            # ë³€ë™ì„±
            volatility = parser.calculate_volatility(grades, student_id)
            
            all_students.append(student_info)
            all_grades.extend(grades)
            all_seteuk.extend(seteuk)
            all_volatility.append(volatility)
            
            print(f"âœ“ (ì„±ì :{len(grades)}, ì„¸íŠ¹:{len(seteuk)})")
        except Exception as e:
            print(f"âŒ {e}")
    
    # DataFrame ìƒì„±
    df_students = pd.DataFrame(all_students)
    df_grades = pd.DataFrame(all_grades)
    df_seteuk = pd.DataFrame(all_seteuk)
    df_volatility = pd.DataFrame(all_volatility)
    df_yearly_covid = create_yearly_covid_data(df_students)
    df_keywords = create_keywords_data(df_seteuk)
    
    # ì €ì¥
    print("\nğŸ’¾ ë°ì´í„° ì €ì¥ ì¤‘...")
    
    files_to_save = {
        'student_info.csv': df_students,
        'students_anonymized.csv': df_students,
        'grades.csv': df_grades,
        'seteuk.csv': df_seteuk,
        'volatility.csv': df_volatility,
        'yearly_covid.csv': df_yearly_covid,
        'keywords.csv': df_keywords,
    }
    
    for filename, dataframe in files_to_save.items():
        try:
            dataframe.to_csv(processed_dir / filename, index=False, encoding='utf-8-sig')
            print(f"  âœ“ {filename} ({len(dataframe)} rows)")
        except Exception as e:
            print(f"  âŒ {filename}: {e}")
    
    # ìš”ì•½
    print("\n" + "="*80)
    print("âœ… íŒŒì‹± ì™„ë£Œ!")
    print("="*80)
    print(f"\nğŸ“Š í•™ìƒ ìˆ˜: {len(df_students)}ëª…")
    print(f"ğŸ“Š ì„±ì  ë ˆì½”ë“œ: {len(df_grades)}ê±´")
    print(f"ğŸ“Š ì„¸íŠ¹ ë ˆì½”ë“œ: {len(df_seteuk)}ê±´")
    
    if 'covid_intensity' in df_students.columns:
        print(f"\nğŸ“Š ì½”ë¡œë‚˜ ì˜í–¥ ê°•ë„ ë¶„í¬ (ì˜í–¥ë°›ì€ í•™ë…„ ìˆ˜):")
        for intensity in sorted(df_students['covid_intensity'].unique()):
            count = (df_students['covid_intensity'] == intensity).sum()
            label = "ë¯¸ê²½í—˜" if intensity == 0 else f"{int(intensity)}ê°œ í•™ë…„"
            print(f"   - {label}: {count}ëª…")
    
    if 'any_covid' in df_students.columns:
        covid_count = df_students['any_covid'].sum()
        print(f"\nğŸ“Š ì½”ë¡œë‚˜ ê²½í—˜:")
        print(f"   - ìˆìŒ: {covid_count}ëª…")
        print(f"   - ì—†ìŒ: {len(df_students) - covid_count}ëª…")


if __name__ == "__main__":
    main()