"""
STEP 1: ìƒí™œê¸°ë¡ë¶€ íŒŒì‹± (ì™„ì „ í˜¸í™˜ ë²„ì „)
=========================================
ê°œì„ ì‚¬í•­:
1. thefuzz í¼ì§€ ë§¤ì¹­ (Levenshtein Distance)
2. SHA-256 ë¹„ì‹ë³„í™”
3. ëª¨ë“  step íŒŒì¼ê³¼ ì™„ë²½ í˜¸í™˜
4. ìš©ëŸ‰-ë°˜ì‘ ë¶„ì„ìš© covid_intensity ì¶”ê°€

ì‘ì„±ì¼: 2025
"""

import os
import re
import hashlib
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from collections import Counter
import warnings
warnings.filterwarnings('ignore')

# thefuzz ì„í¬íŠ¸ (ì„¤ì¹˜ ì•ˆ ë˜ì–´ ìˆìœ¼ë©´ ê¸°ë³¸ ë§¤ì¹­ ì‚¬ìš©)
try:
    from thefuzz import fuzz, process
    FUZZY_AVAILABLE = True
except ImportError:
    FUZZY_AVAILABLE = False
    print("âš ï¸  thefuzz ë¯¸ì„¤ì¹˜ - ê¸°ë³¸ ë§¤ì¹­ ì‚¬ìš© (pip install thefuzz python-Levenshtein)")


class StudentRecordParser:
    """ìƒí™œê¸°ë¡ë¶€ íŒŒì„œ (ì™„ì „ í˜¸í™˜ ë²„ì „)"""
    
    def __init__(self):
        # êµìœ¡ë¶€ ê³µì‹ ê³¼ëª© ë¦¬ìŠ¤íŠ¸
        self.all_subjects = [
            'ê³µí†µêµ­ì–´1', 'ê³µí†µêµ­ì–´2', 'ê³µí†µìˆ˜í•™1', 'ê³µí†µìˆ˜í•™2', 'ê³µí†µì˜ì–´1', 'ê³µí†µì˜ì–´2',
            'í•œêµ­ì‚¬1', 'í•œêµ­ì‚¬2', 'í†µí•©ì‚¬íšŒ1', 'í†µí•©ì‚¬íšŒ2', 'í†µí•©ê³¼í•™1', 'í†µí•©ê³¼í•™2',
            'ê³¼í•™íƒêµ¬ì‹¤í—˜1', 'ê³¼í•™íƒêµ¬ì‹¤í—˜2', 'ê¸°ë³¸ìˆ˜í•™1', 'ê¸°ë³¸ìˆ˜í•™2', 'ê¸°ë³¸ì˜ì–´1', 'ê¸°ë³¸ì˜ì–´2',
            'êµ­ì–´', 'ìˆ˜í•™', 'ì˜ì–´', 'í•œêµ­ì‚¬', 'í†µí•©ì‚¬íšŒ', 'í†µí•©ê³¼í•™', 'ê³¼í•™íƒêµ¬ì‹¤í—˜',
            'í™”ë²•ê³¼ ì‘ë¬¸', 'ë…ì„œ', 'ì–¸ì–´ì™€ ë§¤ì²´', 'ë¬¸í•™', 'ì‹¤ìš© êµ­ì–´', 'ì‹¬í™” êµ­ì–´',
            'ê³ ì „ ì½ê¸°', 'í™”ë²•ê³¼ ì–¸ì–´', 'ë…ì„œì™€ ì‘ë¬¸', 'ì£¼ì œ íƒêµ¬ ë…ì„œ', 'ë¬¸í•™ê³¼ ì˜ìƒ',
            'ì§ë¬´ ì˜ì‚¬ì†Œí†µ', 'ë…ì„œ í† ë¡ ê³¼ ê¸€ì“°ê¸°', 'ë§¤ì²´ ì˜ì‚¬ì†Œí†µ', 'ì–¸ì–´ìƒí™œ íƒêµ¬',
            'ìˆ˜í•™â… ', 'ìˆ˜í•™â…¡', 'ë¯¸ì ë¶„', 'í™•ë¥ ê³¼ í†µê³„', 'ì‹¤ìš© ìˆ˜í•™', 'ê¸°í•˜', 'ê²½ì œ ìˆ˜í•™',
            'ìˆ˜í•™ê³¼ì œ íƒêµ¬', 'ê¸°ë³¸ ìˆ˜í•™', 'ì¸ê³µì§€ëŠ¥ ìˆ˜í•™', 'ëŒ€ìˆ˜', 'ë¯¸ì ë¶„I', 'ë¯¸ì ë¶„II',
            'ì§ë¬´ ìˆ˜í•™', 'ìˆ˜í•™ê³¼ ë¬¸í™”', 'ì‹¤ìš© í†µê³„', 'ìˆ˜í•™ 1', 'ìˆ˜í•™ I', 'ìˆ˜í•™ II',
            'ì˜ì–´íšŒí™”', 'ì˜ì–´â… ', 'ì˜ì–´ë…í•´ì™€ ì‘ë¬¸', 'ì˜ì–´â…¡', 'ì‹¤ìš©ì˜ì–´', 'ì˜ì–´ê¶Œ ë¬¸í™”',
            'ì§„ë¡œ ì˜ì–´', 'ì˜ë¯¸ ë¬¸í•™ ì½ê¸°', 'ê¸°ë³¸ ì˜ì–´', 'ì˜ì–´ ë°œí‘œì™€ í† ë¡ ', 'ì‹¬í™” ì˜ì–´',
            'ì‹¬í™” ì˜ì–´ ë…í•´ì™€ ì‘ë¬¸', 'ì§ë¬´ ì˜ì–´', 'ì‹¤ìƒí™œ ì˜ì–´ íšŒí™”', 'ë¯¸ë””ì–´ ì˜ì–´',
            'ì„¸ê³„ ë¬¸í™”ì™€ ì˜ì–´', 'ì‹¤ìš© ì˜ì–´íšŒí™”', 'ì‹¤ìš©ì˜ì–´ I', 'ì˜ì–´ II', 'ì˜ì–´ I',
            'í•œêµ­ì§€ë¦¬', 'ì„¸ê³„ì§€ë¦¬', 'ì„¸ê³„ì‚¬', 'ë™ì•„ì‹œì•„ì‚¬', 'ê²½ì œ', 'ì •ì¹˜ì™€ ë²•', 'ì‚¬íšŒÂ·ë¬¸í™”',
            'ìƒí™œê³¼ ìœ¤ë¦¬', 'ìœ¤ë¦¬ì™€ ì‚¬ìƒ', 'ì—¬í–‰ì§€ë¦¬', 'ì‚¬íšŒë¬¸ì œ íƒêµ¬', 'ê³ ì „ê³¼ ìœ¤ë¦¬',
            'ì„¸ê³„ì‹œë¯¼ê³¼ ì§€ë¦¬', 'í˜„ëŒ€ì‚¬íšŒì™€ ìœ¤ë¦¬', 'í•œêµ­ì§€ë¦¬ íƒêµ¬', 'ë„ì‹œì˜ ë¯¸ë˜ íƒêµ¬',
            'ë™ì•„ì‹œì•„ ì—­ì‚¬ ê¸°í–‰', 'ë²•ê³¼ ì‚¬íšŒ', 'ì¸ë¬¸í•™ê³¼ ìœ¤ë¦¬', 'êµ­ì œ ê´€ê³„ì˜ ì´í•´',
            'ì—­ì‚¬ë¡œ íƒêµ¬í•˜ëŠ” í˜„ëŒ€ ì„¸ê³„', 'ê¸ˆìœµê³¼ ê²½ì œìƒí™œ', 'ìœ¤ë¦¬ë¬¸ì œ íƒêµ¬',
            'ê¸°í›„ë³€í™”ì™€ ì§€ì†ê°€ëŠ¥í•œ ì„¸ê³„', 'ì‚¬íšŒ', 'í˜„ëŒ€ ì„¸ê³„ì˜ ë³€í™”',
            'ë¬¼ë¦¬í•™â… ', 'í™”í•™â… ', 'ìƒëª…ê³¼í•™â… ', 'ì§€êµ¬ê³¼í•™â… ', 'ë¬¼ë¦¬í•™â…¡', 'í™”í•™â…¡',
            'ìƒëª…ê³¼í•™â…¡', 'ì§€êµ¬ê³¼í•™â…¡', 'ê³¼í•™ì‚¬', 'ìƒí™œê³¼ ê³¼í•™', 'ìœµí•©ê³¼í•™', 'ê³¼í•™',
            'ë¬¼ë¦¬í•™ I', 'í™”í•™ I', 'ìƒëª…ê³¼í•™ I', 'ì§€êµ¬ê³¼í•™ I',
            'ì²´ìœ¡', 'ìš´ë™ê³¼ ê±´ê°•', 'ìŠ¤í¬ì¸  ìƒí™œ', 'ì²´ìœ¡ íƒêµ¬',
            'ìŒì•…', 'ë¯¸ìˆ ', 'ì—°ê·¹', 'ìŒì•… ì—°ì£¼', 'ìŒì•… ê°ìƒê³¼ ë¹„í‰',
            'ë¯¸ìˆ  ì°½ì‘', 'ë¯¸ìˆ  ê°ìƒê³¼ ë¹„í‰',
            'ê¸°ìˆ Â·ê°€ì •', 'ì •ë³´', 'ë†ì—… ìƒëª… ê³¼í•™', 'ê³µí•™ ì¼ë°˜', 'ì°½ì˜ ê²½ì˜',
            'í•´ì–‘ ë¬¸í™”ì™€ ê¸°ìˆ ', 'ê°€ì •ê³¼í•™', 'ì§€ì‹ ì¬ì‚° ì¼ë°˜', 'ì¸ê³µì§€ëŠ¥ ê¸°ì´ˆ', 'ì² í•™', 'ê¸°ìˆ  . ê°€ì •',
            'ë…ì¼ì–´I', 'í”„ë‘ìŠ¤ì–´I', 'ìŠ¤í˜ì¸ì–´I', 'ì¤‘êµ­ì–´I', 'ì¼ë³¸ì–´I', 'ëŸ¬ì‹œì•„ì–´I',
            'ì•„ëì–´I', 'ë² íŠ¸ë‚¨ì–´I', 'ë…ì¼ì–´II', 'í”„ë‘ìŠ¤ì–´II', 'ìŠ¤í˜ì¸ì–´II', 'ì¤‘êµ­ì–´II',
            'ì¼ë³¸ì–´II', 'ëŸ¬ì‹œì•„ì–´II', 'ì•„ëì–´II', 'ë² íŠ¸ë‚¨ì–´II', 'ì¼ë³¸ì–´ I',
            'í•œë¬¸I', 'í•œë¬¸II', 'í•œë¬¸ I', 'ì² í•™', 'ë…¼ë¦¬í•™', 'ì‹¬ë¦¬í•™', 'êµìœ¡í•™', 'ì¢…êµí•™',
            'ì§„ë¡œì™€ ì§ì—…', 'ë³´ê±´', 'í™˜ê²½', 'ì‹¤ìš© ê²½ì œ', 'ë…¼ìˆ ', 'ì•ˆì „í•œ ìƒí™œ'
        ]
        
        # êµê³¼êµ° ë§¤í•‘
        self.subject_to_group = self._build_subject_group_map()
        
        # í‚¤ì›Œë“œ ì •ì˜
        self.exploration_keywords = [
            'ì‹¤í—˜', 'ì‹¤ìŠµ', 'ê´€ì°°', 'ì¸¡ì •', 'ë¶„ì„', 'íƒêµ¬', 'ì—°êµ¬', 'ì¡°ì‚¬',
            'íƒìƒ‰', 'ë°œê²¬', 'í˜„ì¥', 'ë‹µì‚¬', 'ê²¬í•™', 'ë°©ë¬¸', 'ì²´í—˜', 'ì‹¤ì‚¬',
            'í”„ë¡œì íŠ¸', 'ê³¼ì œì—°êµ¬', 'íŒ€í”„ë¡œì íŠ¸', 'ëª¨ë‘ í™œë™', 'ì†Œì§‘ë‹¨',
            'ê°€ì„¤', 'ê²€ì¦', 'ì‹¤í—˜ì„¤ê³„', 'ë°ì´í„°ìˆ˜ì§‘', 'ê²°ê³¼ë¶„ì„', 'ë³´ê³ ì„œì‘ì„±'
        ]
        
        self.online_keywords = [
            'ì˜¨ë¼ì¸', 'ì›ê²©', 'ë¹„ëŒ€ë©´', 'í™”ìƒ', 'ì‹¤ì‹œê°„', 'ìŒë°©í–¥',
            'zoom', 'ì¤Œ', 'ZOOM', 'êµ¬ê¸€í´ë˜ìŠ¤ë£¸', 'í´ë˜ìŠ¤ë£¸', 'e-í•™ìŠµí„°',
            'ì´í•™ìŠµí„°', 'EBS', 'ebs', 'ìœ„ë‘ë‘', 'ë””ì§€í„¸', 'ì¸í„°ë„·',
            'ì›ê²©ìˆ˜ì—…', 'ì˜¨ë¼ì¸ìˆ˜ì—…', 'í™”ìƒìˆ˜ì—…', 'ë™ì˜ìƒ', 'ì˜ìƒ'
        ]
        
        self.qualitative_keywords = [
            'ê³¼ì •', 'ë…¸ë ¥', 'íƒœë„', 'ì°¸ì—¬', 'ì—´ì •', 'ëª°ì…', 'ì§‘ì¤‘',
            'í˜‘ë ¥', 'í˜‘ë™', 'ë°°ë ¤', 'ë‚˜ëˆ”', 'ì†Œí†µ', 'ê³µê°', 'ì¡´ì¤‘',
            'ì„±ì¥', 'ë°œì „', 'ê°œì„ ', 'ê·¹ë³µ', 'ë„ì „', 'ë³€í™”', 'ì§„ë³´'
        ]
        
        # ì„±ì  ë“±ê¸‰ ë§¤í•‘
        self.grade_map = {
            'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5,
            '1': 1, '2': 2, '3': 3, '4': 4, '5': 5,
            '6': 6, '7': 7, '8': 8, '9': 9,
            'ìˆ˜': 1, 'ìš°': 2, 'ë¯¸': 3, 'ì–‘': 4, 'ê°€': 5
        }
    
    def _build_subject_group_map(self) -> Dict[str, str]:
        """êµê³¼êµ° ë§¤í•‘ ìƒì„±"""
        mapping = {}
        for subject in self.all_subjects:
            if any(kw in subject for kw in ['êµ­ì–´', 'í™”ë²•', 'ì‘ë¬¸', 'ë…ì„œ', 'ì–¸ì–´', 'ë§¤ì²´', 'ë¬¸í•™', 'ê³ ì „']):
                mapping[subject] = 'êµ­ì–´'
            elif any(kw in subject for kw in ['ìˆ˜í•™', 'ë¯¸ì ë¶„', 'í™•ë¥ ', 'í†µê³„', 'ê¸°í•˜', 'ëŒ€ìˆ˜']):
                mapping[subject] = 'ìˆ˜í•™'
            elif any(kw in subject for kw in ['ì˜ì–´', 'English']):
                mapping[subject] = 'ì˜ì–´'
            elif any(kw in subject for kw in ['ì—­ì‚¬', 'í•œêµ­ì‚¬', 'ì„¸ê³„ì‚¬', 'ë™ì•„ì‹œì•„', 'ì§€ë¦¬', 'ê²½ì œ', 'ì •ì¹˜', 'ë²•', 'ì‚¬íšŒ', 'ìœ¤ë¦¬']):
                mapping[subject] = 'ì‚¬íšŒ'
            elif any(kw in subject for kw in ['ê³¼í•™', 'ë¬¼ë¦¬', 'í™”í•™', 'ìƒëª…', 'ì§€êµ¬', 'ìœµí•©', 'íƒêµ¬ì‹¤í—˜']):
                mapping[subject] = 'ê³¼í•™'
            elif any(kw in subject for kw in ['ì²´ìœ¡', 'ìš´ë™', 'ìŠ¤í¬ì¸ ']):
                mapping[subject] = 'ì²´ìœ¡'
            elif any(kw in subject for kw in ['ìŒì•…', 'ë¯¸ìˆ ', 'ì—°ê·¹', 'ì˜ˆìˆ ']):
                mapping[subject] = 'ì˜ˆìˆ '
            elif any(kw in subject for kw in ['ê¸°ìˆ ', 'ê°€ì •', 'ì •ë³´', 'ë†ì—…', 'ê³µí•™']):
                mapping[subject] = 'ê¸°ìˆ Â·ê°€ì •'
            elif any(kw in subject for kw in ['ë…ì¼ì–´', 'í”„ë‘ìŠ¤ì–´', 'ìŠ¤í˜ì¸ì–´', 'ì¤‘êµ­ì–´', 'ì¼ë³¸ì–´', 'ëŸ¬ì‹œì•„ì–´']):
                mapping[subject] = 'ì œ2ì™¸êµ­ì–´'
            else:
                mapping[subject] = 'êµì–‘'
        return mapping
    
    @staticmethod
    def generate_anonymous_id(name: str, student_id: str) -> str:
        """SHA-256 í•´ì‹±ì„ í†µí•œ ë¹„ì‹ë³„í™” ID ìƒì„±"""
        combined = f"{name}_{student_id}"
        return hashlib.sha256(combined.encode('utf-8')).hexdigest()[:16]
    
    def fuzzy_match_subject(self, query: str, threshold: int = 80) -> Tuple[Optional[str], int]:
        """í¼ì§€ ë§¤ì¹­ìœ¼ë¡œ ê³¼ëª©ëª… ì°¾ê¸°"""
        if not query or len(query) < 2:
            return None, 0
        
        # ì •í™• ë§¤ì¹­ ë¨¼ì €
        if query in self.all_subjects:
            return query, 100
        
        # thefuzz ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ í¼ì§€ ë§¤ì¹­
        if FUZZY_AVAILABLE:
            result = process.extractOne(query, self.all_subjects, scorer=fuzz.token_sort_ratio)
            if result and result[1] >= threshold:
                return result[0], result[1]
        
        # ë¶€ë¶„ ë§¤ì¹­
        for subject in self.all_subjects:
            if query in subject or subject in query:
                return subject, 80
        
        return None, 0
    
    def extract_years_from_text(self, text: str) -> List[int]:
        """í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë“  ì—°ë„ ì¶”ì¶œ"""
        patterns = [
            r'(20\d{2})[\.,\-/]\s*\d{2}[\.,\-/]\s*\d{2}',
            r'\((20\d{2})\)',
            r'(20\d{2})ë…„',
        ]
        
        all_years = []
        for pattern in patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                try:
                    year = int(match)
                    if 2010 <= year <= 2025:
                        all_years.append(year)
                except:
                    pass
        return all_years
    
    def estimate_grade_years(self, text: str, filename: str) -> Dict[int, int]:
        """í•™ë…„ë³„ ì—°ë„ ì¶”ì • (ìˆ˜ìƒê²½ë ¥ ë˜ëŠ” ë¹ˆë„ ë¶„ì„)"""
        grade_years = {}
        
        # ìˆ˜ìƒê²½ë ¥ì—ì„œ ì—°ë„-í•™ë…„ íŒ¨í„´ ì°¾ê¸°
        award_patterns = [
            r'(20\d{2})[\./\-]\d{2}[\./\-]\d{2}\s*(\d)í•™ë…„',
            r'(20\d{2})ë…„.*?(\d)í•™ë…„',
        ]
        
        for pattern in award_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                try:
                    year, grade = int(match[0]), int(match[1])
                    if 1 <= grade <= 4 and 2015 <= year <= 2025:
                        if grade not in grade_years:
                            grade_years[grade] = year
                except:
                    pass
        
        # ìˆ˜ìƒê²½ë ¥ì—ì„œ ëª» ì°¾ìœ¼ë©´ ë¹ˆë„ ë¶„ì„
        if not grade_years:
            all_years = self.extract_years_from_text(text)
            if all_years:
                year_counter = Counter(all_years)
                top_years = sorted([y for y, _ in year_counter.most_common(3)])
                if len(top_years) >= 3:
                    grade_years = {1: top_years[0], 2: top_years[1], 3: top_years[2]}
                elif len(top_years) >= 1:
                    base_year = top_years[0]
                    grade_years = {1: base_year, 2: base_year + 1, 3: base_year + 2}
        
        return grade_years
    
    def extract_remote_days(self, text: str) -> Dict[int, int]:
        """í•™ë…„ë³„ ì›ê²©ìˆ˜ì—…ì¼ìˆ˜ ì¶”ì¶œ (ë‹¤ì–‘í•œ ì˜¤íƒ€ íŒ¨í„´ ì§€ì›)"""
        patterns = [
            r'ì›ê²©\s*ìˆ˜ì—…\s*ì¼ìˆ˜?\s*(\d+)\s*ì¼?',
            r'ì›ê²©\s*ì¼ìˆ˜?\s*(\d+)\s*ì¼?',
            r'ì¸ê²©\s*ìˆ˜ì—…\s*ì¼ìˆ˜?\s*(\d+)\s*ì¼?',  # ì˜¤íƒ€: ì›ê²©â†’ì¸ê²©
            r'ì›ê²©\s*ìˆ˜ì…\s*ì¼ìˆ˜?\s*(\d+)\s*ì¼?',  # ì˜¤íƒ€: ìˆ˜ì—…â†’ìˆ˜ì…
            r'ì¸ê²©\s*ìˆ˜ì…\s*ì¼ìˆ˜?\s*(\d+)\s*ì¼?',  # ë³µí•© ì˜¤íƒ€
            r'ì›ê²©ìˆ˜ì—…ì¼ìˆ˜(\d+)ì¼?',
            r'ì¸ê²©ìˆ˜ì—…ì¼ìˆ˜(\d+)ì¼?',
            r'ì›ê²©ìˆ˜ì…ì¼ìˆ˜(\d+)ì¼?',
            r'ê°œê·¼\s*[,.\s]*ì›ê²©\s*ìˆ˜ì—…?\s*ì¼ìˆ˜?\s*(\d+)\s*ì¼?',
        ]
        
        all_remote_values = []
        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                try:
                    value = int(match)
                    if 0 <= value <= 200:
                        all_remote_values.append(value)
                except:
                    pass
        
        # í•™ë…„ë³„ ì„¹ì…˜ ë¶„ë¦¬
        remote_by_grade = {1: 0, 2: 0, 3: 0}
        sections = re.split(r'\[(\d)í•™ë…„\]', text)
        
        for i in range(1, len(sections), 2):
            try:
                grade = int(sections[i])
                section_text = sections[i + 1] if i + 1 < len(sections) else ""
                
                for pattern in patterns:
                    matches = re.findall(pattern, section_text, re.IGNORECASE)
                    for match in matches:
                        try:
                            value = int(match)
                            if value > 0 and value <= 200:
                                remote_by_grade[grade] = max(remote_by_grade.get(grade, 0), value)
                        except:
                            pass
            except:
                pass
        
        return remote_by_grade
    
    def parse_student_info(self, text: str, filename: str) -> Optional[Dict]:
        """í•™ìƒ ì •ë³´ íŒŒì‹±"""
        try:
            parts = filename.replace('.txt', '').split('_')
            if len(parts) < 4:
                return None
            
            student_id = parts[0]
            grade = parts[1].replace('í•™ë…„', '')
            major = parts[2]
            name = parts[3]
            admission_type = parts[4] if len(parts) > 4 else 'unknown'
            
            # ë¹„ì‹ë³„í™” ID ìƒì„±
            anonymous_id = self.generate_anonymous_id(name, student_id)
            
            # í•™ë…„ë³„ ì—°ë„ ì¶”ì •
            grade_years = self.estimate_grade_years(text, filename)
            
            # ì›ê²©ìˆ˜ì—…ì¼ìˆ˜ ì¶”ì¶œ
            remote_days = self.extract_remote_days(text)
            total_remote_days = sum(remote_days.values())
            
            # ì½”ë¡œë‚˜ ì—¬ë¶€ íŒë‹¨ (2020~2022ë…„)
            grade1_covid = 1 if grade_years.get(1) and 2020 <= grade_years[1] <= 2022 else 0
            grade2_covid = 1 if grade_years.get(2) and 2020 <= grade_years[2] <= 2022 else 0
            grade3_covid = 1 if grade_years.get(3) and 2020 <= grade_years[3] <= 2022 else 0
            
            # ì½”ë¡œë‚˜ ê°•ë„ (0~3): ìš©ëŸ‰-ë°˜ì‘ ë¶„ì„ìš©
            covid_intensity = grade1_covid + grade2_covid + grade3_covid
            any_covid = 1 if covid_intensity > 0 else 0
            
            # ê³ êµ ì¡¸ì—…ë…„ë„ ì¶”ì •
            hs_graduation_year = grade_years.get(3, 0) if grade_years.get(3) else None
            
            return {
                # ê¸°ë³¸ ì •ë³´ (ë¹„ì‹ë³„í™”)
                'student_id': anonymous_id,  # step3/step4 í˜¸í™˜ìš©
                'anonymous_id': anonymous_id,
                'name': name,  # step5ì—ì„œ ì°¸ì¡°, ì‹¤ì œ ì €ì¥ ì‹œ ì‚­ì œ
                'grade': int(grade) if grade.isdigit() else 0,
                'major': major,
                'admission_type': admission_type,
                
                # ì—°ë„ ì •ë³´
                'grade_year_1': grade_years.get(1),
                'grade_year_2': grade_years.get(2),
                'grade_year_3': grade_years.get(3),
                'hs_graduation_year': hs_graduation_year,
                'admission_year': hs_graduation_year,
                'graduation_year': hs_graduation_year,
                
                # ì½”ë¡œë‚˜ ê´€ë ¨ (ë‹¤ì–‘í•œ ì»¬ëŸ¼ëª… í˜¸í™˜)
                'grade1_covid': grade1_covid,
                'grade2_covid': grade2_covid,
                'grade3_covid': grade3_covid,
                'covid_intensity': covid_intensity,  # ìš©ëŸ‰-ë°˜ì‘ ë¶„ì„ìš© (0~3)
                'any_covid': any_covid,
                'has_covid': any_covid,  # step3 í˜¸í™˜
                'has_covid_period': any_covid,  # step4 í˜¸í™˜
                'covid_period': any_covid,  # step5 í˜¸í™˜
                
                # ì›ê²©ìˆ˜ì—…
                'remote_days_grade1': remote_days.get(1, 0),
                'remote_days_grade2': remote_days.get(2, 0),
                'remote_days_grade3': remote_days.get(3, 0),
                'total_remote_days': total_remote_days,
                
                # ë©”íƒ€ë°ì´í„°
                'is_repeat': 0,
                'grade_years': grade_years,
                'remote_days': remote_days,
            }
        except Exception as e:
            print(f"  âŒ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None
    
    def extract_grades(self, text: str, student_id: str, grade_years: Dict) -> List[Dict]:
        """ì„±ì  ë°ì´í„° ì¶”ì¶œ"""
        grades = []
        
        # í•™ë…„ë³„ ì„¹ì…˜ ë¶„ë¦¬
        sections = re.split(r'\[(\d)í•™ë…„\]', text)
        
        # ì„±ì  íŒ¨í„´
        pattern = r'([ê°€-í£A-Za-z\s./â… -â…©]+?)\s+(\d+)\s+(\d+)/(\d+\.?\d*)\((\d+\.?\d*)\)\s+([A-E1-9ìˆ˜ìš°ë¯¸ì–‘ê°€])\((\d+)\)'
        
        for i in range(1, len(sections), 2):
            try:
                grade_year = int(sections[i])
                section_text = sections[i + 1] if i + 1 < len(sections) else ""
                year = grade_years.get(grade_year)
                
                for match in re.finditer(pattern, section_text):
                    subject_raw = match.group(1).strip()
                    subject_matched, score = self.fuzzy_match_subject(subject_raw)
                    subject = subject_matched if subject_matched else subject_raw
                    
                    achievement = match.group(6)
                    grade_numeric = self.grade_map.get(achievement)
                    
                    if grade_numeric:
                        grade_type = 'achievement' if achievement in 'ABCDEìˆ˜ìš°ë¯¸ì–‘ê°€' else 'rank'
                        
                        grades.append({
                            'student_id': student_id,
                            'grade_year': grade_year,
                            'year': year,
                            'term': 1,
                            'subject': subject,
                            'subject_raw': subject_raw,
                            'subject_group': self.subject_to_group.get(subject, 'êµì–‘'),
                            'units': int(match.group(2)),
                            'raw_score': int(match.group(3)),
                            'average': float(match.group(4)),
                            'std_dev': float(match.group(5)),
                            'achievement': achievement,
                            'grade_numeric': grade_numeric,
                            'grade_type': grade_type,
                            'num_students': int(match.group(7)),
                            'match_score': score,
                        })
            except:
                pass
        
        return grades
    
    def extract_seteuk(self, text: str, student_id: str, grade_years: Dict) -> List[Dict]:
        """ì„¸íŠ¹ ë°ì´í„° ì¶”ì¶œ"""
        seteuk_list = []
        
        # ì„¸íŠ¹ íŒ¨í„´
        patterns = [
            r'\[ì„¸ë¶€ëŠ¥ë ¥íŠ¹ê¸°ì‚¬í•­\]\s*([ê°€-í£A-Za-z\s./â… -â…©]+?)\s*:\s*(.+?)(?=\[ì„¸ë¶€ëŠ¥ë ¥íŠ¹ê¸°ì‚¬í•­\]|\[|$)',
            r'ì„¸ë¶€ëŠ¥ë ¥\s*ë°\s*íŠ¹ê¸°ì‚¬í•­[:\s]*(.+?)(?=\d+\.\s*[ê°€-í£]|\[|$)',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text, re.DOTALL)
            for match in matches:
                if len(match) == 2:
                    subject, content = match
                else:
                    subject, content = "ê¸°íƒ€", match[0] if match else ""
                
                content = content.strip()
                if len(content) < 10:
                    continue
                
                # í‚¤ì›Œë“œ ë¹ˆë„ ê³„ì‚°
                content_len = len(content)
                exp_count = sum(1 for kw in self.exploration_keywords if kw in content)
                online_count = sum(1 for kw in self.online_keywords if kw in content)
                qual_count = sum(1 for kw in self.qualitative_keywords if kw in content)
                
                seteuk_list.append({
                    'student_id': student_id,
                    'subject': subject.strip(),
                    'content_length': content_len,
                    'kw_count_exploration': exp_count,
                    'kw_count_online': online_count,
                    'kw_count_qualitative': qual_count,
                    'kw_freq_exploration': exp_count / content_len * 1000 if content_len > 0 else 0,
                    'kw_freq_online': online_count / content_len * 1000 if content_len > 0 else 0,
                    'kw_freq_qualitative': qual_count / content_len * 1000 if content_len > 0 else 0,
                })
        
        return seteuk_list
    
    def calculate_volatility(self, grades: List[Dict], student_id: str, remote_days: Dict) -> Dict:
        """ì„±ì  ë³€ë™ì„± ê³„ì‚°"""
        result = {'student_id': student_id}
        
        if not grades:
            return result
        
        df = pd.DataFrame(grades)
        
        # ì „ì²´ ë³€ë™ì„±
        if 'grade_numeric' in df.columns:
            result['overall_volatility'] = df['grade_numeric'].std()
            result['overall_mean'] = df['grade_numeric'].mean()
            result['overall_count'] = len(df)
        
        # í•™ë…„ë³„ ë³€ë™ì„±
        for grade in [1, 2, 3]:
            grade_df = df[df['grade_year'] == grade]
            if len(grade_df) >= 2:
                result[f'grade{grade}_volatility'] = grade_df['grade_numeric'].std()
                result[f'grade{grade}_mean'] = grade_df['grade_numeric'].mean()
                result[f'grade{grade}_count'] = len(grade_df)
                result[f'grade{grade}_remote_days'] = remote_days.get(grade, 0)
        
        return result


def create_yearly_covid_data(df_students: pd.DataFrame) -> pd.DataFrame:
    """yearly_covid.csv ìƒì„± (step3/step4 í˜¸í™˜)"""
    yearly_data = []
    
    for _, student in df_students.iterrows():
        student_id = student['anonymous_id']
        
        for grade in [1, 2, 3]:
            year = student.get(f'grade_year_{grade}')
            covid = student.get(f'grade{grade}_covid', 0)
            
            if year:
                yearly_data.append({
                    'anonymous_id': student_id,
                    'student_id': student_id,
                    'grade': grade,
                    'year': int(year),
                    'is_covid_period': covid,
                })
    
    return pd.DataFrame(yearly_data)


def create_keywords_data(df_seteuk: pd.DataFrame) -> pd.DataFrame:
    """keywords.csv ìƒì„± (step4 í˜¸í™˜)"""
    if df_seteuk.empty:
        return pd.DataFrame()
    
    keywords = df_seteuk.groupby('student_id').agg({
        'kw_count_exploration': 'sum',
        'kw_count_online': 'sum',
        'kw_count_qualitative': 'sum',
    }).reset_index()
    
    keywords.columns = ['anonymous_id', 'exploration_total', 'remote_total', 'qualitative_total']
    return keywords


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("="*80)
    print("STEP 1: ìƒí™œê¸°ë¡ë¶€ íŒŒì‹± (ì™„ì „ í˜¸í™˜ ë²„ì „)")
    print("="*80)
    
    input_dir = Path('data/raw')
    output_dir = Path('data/processed')
    results_dir = Path('data/results')
    output_dir.mkdir(parents=True, exist_ok=True)
    results_dir.mkdir(parents=True, exist_ok=True)
    
    txt_files = list(input_dir.glob('*.txt'))
    print(f"\nì´ {len(txt_files)}ê°œ íŒŒì¼ ë°œê²¬")
    
    if len(txt_files) == 0:
        print("âš ï¸  data/raw/ ë””ë ‰í† ë¦¬ì— txt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    parser = StudentRecordParser()
    
    all_students = []
    all_grades = []
    all_seteuk = []
    all_volatility = []
    
    print("\níŒŒì‹± ì§„í–‰ ì¤‘...")
    for i, filepath in enumerate(txt_files, 1):
        print(f"  [{i}/{len(txt_files)}] {filepath.name}...", end=' ')
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                text = f.read()
            
            student_info = parser.parse_student_info(text, filepath.name)
            if not student_info:
                print("âŒ")
                continue
            
            student_id = student_info['anonymous_id']
            grade_years = student_info['grade_years']
            remote_days = student_info['remote_days']
            
            all_students.append(student_info)
            
            grades = parser.extract_grades(text, student_id, grade_years)
            all_grades.extend(grades)
            
            seteuk = parser.extract_seteuk(text, student_id, grade_years)
            all_seteuk.extend(seteuk)
            
            volatility = parser.calculate_volatility(grades, student_id, remote_days)
            all_volatility.append(volatility)
            
            print("âœ“")
        except Exception as e:
            print(f"âŒ {e}")
    
    # DataFrame ìƒì„±
    df_students = pd.DataFrame(all_students)
    df_grades = pd.DataFrame(all_grades)
    df_seteuk = pd.DataFrame(all_seteuk)
    df_volatility = pd.DataFrame(all_volatility)
    
    # ì¶”ê°€ ë°ì´í„° ìƒì„± (step3/step4 í˜¸í™˜)
    df_yearly_covid = create_yearly_covid_data(df_students)
    df_keywords = create_keywords_data(df_seteuk)
    
    # í•™ìƒ ì •ë³´ì—ì„œ ë‚´ë¶€ ë°ì´í„° ì œê±° í›„ ì €ì¥
    save_columns = [c for c in df_students.columns if c not in ['grade_years', 'remote_days']]
    df_students_save = df_students[save_columns].copy()
    
    print("\nğŸ’¾ ë°ì´í„° ì €ì¥ ì¤‘...")
    
    # CSV ì €ì¥
    csv_files = {
        'student_info.csv': df_students_save,  # step5 í˜¸í™˜
        'students_anonymized.csv': df_students_save,  # step3/step4 í˜¸í™˜
        'grades.csv': df_grades,
        'seteuk.csv': df_seteuk,
        'volatility.csv': df_volatility,
        'yearly_covid.csv': df_yearly_covid,  # step3/step4 í˜¸í™˜
        'keywords.csv': df_keywords,  # step4 í˜¸í™˜
    }
    
    for filename, dataframe in csv_files.items():
        filepath = output_dir / filename
        try:
            dataframe.to_csv(filepath, index=False, encoding='utf-8-sig')
            print(f"  âœ“ {filename} ({len(dataframe)} rows)")
        except Exception as e:
            print(f"  âŒ {filename}: {e}")
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*80)
    print("âœ… íŒŒì‹± ì™„ë£Œ!")
    print("="*80)
    
    print(f"\nğŸ“Š í•™ìƒ ìˆ˜: {len(df_students)}ëª… (ë¹„ì‹ë³„í™”ë¨)")
    print(f"ğŸ“Š ì„±ì  ë ˆì½”ë“œ: {len(df_grades)}ê±´")
    print(f"ğŸ“Š ì„¸íŠ¹ ë ˆì½”ë“œ: {len(df_seteuk)}ê±´")
    
    if 'covid_intensity' in df_students.columns:
        print(f"\nğŸ“Š ì½”ë¡œë‚˜ ì˜í–¥ ê°•ë„ ë¶„í¬ (ìš©ëŸ‰-ë°˜ì‘):")
        for intensity in range(4):
            count = (df_students['covid_intensity'] == intensity).sum()
            pct = count / len(df_students) * 100 if len(df_students) > 0 else 0
            bar = "â–ˆ" * int(pct / 5)
            print(f"   - {intensity}í•™ë…„ ì˜í–¥: {count:3d}ëª… ({pct:5.1f}%) {bar}")
    
    if 'any_covid' in df_students.columns:
        covid_count = df_students['any_covid'].sum()
        print(f"\nğŸ“Š ì½”ë¡œë‚˜ ê²½í—˜:")
        print(f"   - ìˆìŒ: {covid_count}ëª…")
        print(f"   - ì—†ìŒ: {len(df_students) - covid_count}ëª…")
    
    print("\nğŸ’¾ ì €ì¥ëœ íŒŒì¼:")
    print("  - student_info.csv (step5 í˜¸í™˜)")
    print("  - students_anonymized.csv (step3/step4 í˜¸í™˜)")
    print("  - grades.csv")
    print("  - seteuk.csv")
    print("  - volatility.csv")
    print("  - yearly_covid.csv (step3/step4 í˜¸í™˜)")
    print("  - keywords.csv (step4 í˜¸í™˜)")
    
    print("\nâœ¨ Step 1 ì™„ë£Œ!")


if __name__ == "__main__":
    main()